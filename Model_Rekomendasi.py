# -*- coding: utf-8 -*-
"""Model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1aqrU8wBIuiFtqoqvOd6jmg5TtRun9Y5S
"""

import pandas as pd
import numpy as np
import tensorflow as tf
from sklearn.preprocessing import StandardScaler
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
from sklearn.preprocessing import LabelEncoder
from tensorflow.keras.callbacks import Callback

from google.colab import drive
drive.mount('/content/drive')

data_makanan = pd.read_csv('/content/drive/Shared drives/Dataset/Data Makanan Indonesia.csv')
data_pasien_stroke = pd.read_csv('/content/drive/Shared drives/Dataset/Data Training.csv')
print(data_pasien_stroke)

"""PREPROSESSING"""

data_pasien_stroke_baru = data_pasien_stroke.dropna()

data_pasien_stroke_baru['avg_glucose_level'] = data_pasien_stroke_baru['avg_glucose_level'].astype(int)
for index, row in data_pasien_stroke_baru.iterrows():
    if row['avg_glucose_level'] > 100:
        data_pasien_stroke_baru.at[index, 'avg_glucose_level'] = 1
    else:
        data_pasien_stroke_baru.at[index, 'avg_glucose_level'] = 0
data_pasien_stroke_baru.dtypes

"""Memisahkan Fitur"""

feature = data_pasien_stroke_baru[['hypertension', 'heart_disease','avg_glucose_level','bmi']].values
target = data_pasien_stroke_baru['food_code'].values

"""Normalisasi Data"""

# Normalisasi fitur menggunakan StandardScaler
scaler = StandardScaler()
feature = scaler.fit_transform(feature)

feature

"""Splitting Data Train dan Validation"""

X_train=feature
Y_train=target
label_encoder = LabelEncoder()
Y_train_encoded = label_encoder.fit_transform(Y_train)

class SaveBestAccuracyModel(Callback):
    def __init__(self, filepath, monitor='acc', mode='max', save_best_only=True):
        super(SaveBestAccuracyModel, self).__init__()
        self.filepath = filepath
        self.monitor = monitor
        self.mode = mode
        self.save_best_only = save_best_only
        self.best_accuracy = -float('inf') if mode == 'max' else float('inf')

    def on_epoch_end(self, epoch, logs=None):
        current_accuracy = logs.get(self.monitor)
        if current_accuracy is None:
            print("SaveBestAccuracyModel warning: Accuracy metric '{}' not found. Model won't be saved.".format(self.monitor))
            return

        if (self.mode == 'max' and current_accuracy > self.best_accuracy) or \
           (self.mode == 'min' and current_accuracy < self.best_accuracy):

            print("\nSaveBestAccuracyModel: Accuracy improved from {:.4f} to {:.4f}. Saving model to {}"
                  .format(self.best_accuracy, current_accuracy, self.filepath))
            self.best_accuracy = current_accuracy
            self.model.save(self.filepath, overwrite=True)
        elif self.save_best_only and epoch > 0:
            print("\nSaveBestAccuracyModel: Accuracy did not improve from {:.4f}. Model not saved.".format(self.best_accuracy))

"""Model Machine Learning Artificial Neural Network (Content Based Filtering)"""

# Membangun model Neural Network
model = tf.keras.Sequential([
    tf.keras.layers.Dense(8, activation='relu', input_shape=X_train.shape[1:]),
    tf.keras.layers.Dense(16, activation='relu'),
    tf.keras.layers.Dense(32, activation='relu'),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dense(len(np.unique(Y_train_encoded)), activation='softmax')
])
# Mengompilasi model
model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
#Membuat model dengan hasil terbaik
callbacks = [SaveBestAccuracyModel(filepath='Model_Rekomendasi.h5', monitor='accuracy', mode='max', save_best_only=True)]

# Melatih model dengan menggunakan callback
model.fit(X_train, Y_train_encoded, epochs=1000, callbacks=[callbacks])

# model = tf.keras.models.load_model('Model_Rekomendasi.h5')
X_input = np.array([[1,0,1,22]])
X_input = scaler.transform(X_input)

# Menghitung cosine similarity antara fitur input dan fitur latihan
# similarity_scores = cosine_similarity(X_input, X_train)
prediksi = model.predict(X_input)
indeks_nama_makanan = np.argmax(prediksi)
Kode_Makanan = Y_train[indeks_nama_makanan]
print(Kode_Makanan)