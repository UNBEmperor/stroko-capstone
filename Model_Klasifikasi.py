# -*- coding: utf-8 -*-
"""Classification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1HtsM7DkXRJ4Yw-x9ZzQcVLgne2ghberz
"""

import pandas as pd
import numpy as np
import tensorflow as tf
import matplotlib.pyplot as plt
from tensorflow.keras.callbacks import Callback
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import StandardScaler

from google.colab import drive
drive.mount('/content/drive')

# Load dataset
def load_data():
    data = pd.read_csv('/content/drive/Shared drives/Dataset/stroke.csv', delimiter=';')
    pd.set_option('display.max_colwidth', None)
    return data

data = load_data()
data

data['Diabetes'] = np.where(data['Average Glucose Level'] >= 126, 1, 0)
data = data.drop('Average Glucose Level', axis=1)
data.insert(4, 'Diabetes', data.pop('Diabetes'))
data

data.info()

categorical = data.select_dtypes(exclude='number')
categorical

labelencoder = LabelEncoder()

for column in categorical:
    numericColumn = labelencoder.fit_transform(categorical[column])
    data[column] = numericColumn
data

x = data.drop(['Diagnosis'], axis='columns')
standardscaler = StandardScaler()
x_scale = standardscaler.fit_transform(x)
x_scale = pd.DataFrame(x_scale, columns=x.columns)

x = x_scale
y = data['Diagnosis']

x.info()

x

y

x_train, x_test, y_train, y_test = train_test_split(x,y, test_size= 0.3)

print('Training dataset:\n', x_train.shape, y_train.shape)
print('Test dataset:\n', x_test.shape, y_test.shape)

# Inversi transformasi untuk mendapatkan data dalam skala asli
x_restored = standardscaler.inverse_transform(x_train)
restored_data = pd.DataFrame(data=x_restored, columns=x_train.columns)
restored_data = restored_data.drop(columns=['BMI'])
restored_data = restored_data.astype(int)
restored_data.insert(5, 'BMI', x_restored[:, x_train.columns.get_loc('BMI')])
restored_data['Diagnosis'] = labelencoder.inverse_transform(y_train)
restored_data

restored_data.to_csv('traindata.csv', index=False)

class SaveBestAccuracyModel(Callback):
    def __init__(self, filepath, monitor='acc', mode='max', save_best_only=True):
        super(SaveBestAccuracyModel, self).__init__()
        self.filepath = filepath
        self.monitor = monitor
        self.mode = mode
        self.save_best_only = save_best_only
        self.best_accuracy = -float('inf') if mode == 'max' else float('inf')

    def on_epoch_end(self, epoch, logs=None):
        current_accuracy = logs.get(self.monitor)
        if current_accuracy is None:
            print("SaveBestAccuracyModel warning: Accuracy metric '{}' not found. Model won't be saved.".format(self.monitor))
            return

        if (self.mode == 'max' and current_accuracy > self.best_accuracy) or \
           (self.mode == 'min' and current_accuracy < self.best_accuracy):

            print("\nSaveBestAccuracyModel: Accuracy improved from {:.4f} to {:.4f}. Saving model to {}"
                  .format(self.best_accuracy, current_accuracy, self.filepath))
            self.best_accuracy = current_accuracy
            self.model.save(self.filepath, overwrite=True)
        elif self.save_best_only and epoch > 0:
            print("\nSaveBestAccuracyModel: Accuracy did not improve from {:.4f}. Model not saved.".format(self.best_accuracy))

model = tf.keras.Sequential([
    tf.keras.layers.Dense(32, activation='relu', input_shape=x_train.shape[1:]),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dropout(0.5),
    tf.keras.layers.Dense(256, activation='relu'),
    tf.keras.layers.Dense(1, activation='sigmoid')
])

model.summary()

model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])

#Membuat model dengan hasil terbaik
callbacks = [SaveBestAccuracyModel(filepath='Model_Klasifikasi.h5', monitor='accuracy', mode='max', save_best_only=True)]

history = model.fit(x_train, y_train, epochs=500, callbacks=[callbacks])

import matplotlib.pyplot as plt

train_loss = history.history['loss']
train_accuracy = history.history['accuracy']

# Plot kurva loss
plt.figure(figsize=(12, 6))
plt.subplot(1, 2, 1)
plt.plot(train_loss, label='Training Loss')
plt.title('Training Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()

# Plot kurva metrik (misalnya accuracy)
plt.subplot(1, 2, 2)
plt.plot(train_accuracy, label='Training Accuracy')
plt.title('Training')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()

sample_input = np.array([56,0,0,1,1,22.37,2,0,1,0,1]).reshape(1, -1)
scaledDataSample = standardscaler.fit_transform(sample_input)
Diagnosis = model.predict(scaledDataSample)
print("Diagnosis: ", int(np.round(Diagnosis)[0][0]))